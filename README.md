# la-strategie-de-promotion-optimal- 
# üõí Causal Inference for Retail: Maximizing Promotion Profitability

![Python](https://img.shields.io/badge/Python-3.9-blue) ![CausalML](https://img.shields.io/badge/Library-CausalML-orange) ![XGBoost](https://img.shields.io/badge/Model-XGBoost-green) ![Status](https://img.shields.io/badge/Status-Enterprise%20Grade-gold)

## üìâ Executive Summary
This project answers a critical business question: **"Which stores should actually receive a promotion to maximize net profit?"**

Using **Causal Inference (Uplift Modeling)** on the [Rossmann Store Sales dataset](https://www.kaggle.com/c/rossmann-store-sales), I built a meta-learner system to estimate the **Individual Treatment Effect (ITE)** of promotions.

**Key Finding:** 46.5% of promotions were destroying value (generating less sales lift than their operational cost). By optimizing the targeting policy, the model is projected to increase net profit by **+‚Ç¨214M** compared to a blanket promotion strategy.

## üíº The Business Problem
Retailers often apply "blanket promotions" (running sales across all stores). This is inefficient for two reasons:
1.  **The "Sure Things":** Stores that have high organic demand and would sell well without a discount (cannibalization).
2.  **The "Lost Causes":** Stores where the increase in sales is too small to cover the cost of running the promotion.

**Objective:** Shift from predicting *Sales* to predicting *Lift* (Incremental Sales) to optimize ROI.

## üõ†Ô∏è Technical Solution
I implemented a **Causal Meta-Learner** framework to solve the counterfactual problem (*"What would have happened if we didn't run the promo?"*).

### 1. Methodology
* **S-Learner (Baseline):** Trained a Single Learner (Random Forest) treating `Promo` as a feature.
    * *Result:* Failed to discriminate between store segments (Flat Uplift Curve). It learned the average effect but missed heterogeneity.
* **T-Learner (Champion):** Trained "Two Learners" (XGBoost) separately for Treatment and Control groups.
    * *Result:* Successfully captured variance in store sensitivity, creating a high-resolution ranking of opportunities.

### 2. Financial Optimization (Stress Testing)
I performed a sensitivity analysis simulating different promotional costs (‚Ç¨500 - ‚Ç¨2000) to find the "Breaking Point" where the strategy shifts.

## üìä Key Results
The T-Learner successfully segmented the store network into three tiers:

| Segment | Store Count | Avg Lift (‚Ç¨) | Recommendation |
| :--- | :--- | :--- | :--- |
| **Tier 1 (High Uplift)** | Top 25% | **+‚Ç¨2,375** | **‚úÖ Aggressive Push:** High ROI targets. |
| **Tier 2 (Mid Uplift)** | Mid 28% | **+‚Ç¨1,175** | **‚ö†Ô∏è Test & Learn:** Promote during seasonal peaks. |
| **Tier 3 (Negative ROI)** | Bottom 47% | **+‚Ç¨400** | **‚ùå STOP:** Lift is < Cost (‚Ç¨1,100). |

### üìà Impact Analysis
* **Baseline Strategy (Target Everyone):** ‚Ç¨180M Net Profit
* **Causal AI Strategy (Target Top 53%):** ‚Ç¨394M Net Profit
* **Net Business Value:** üöÄ **+‚Ç¨214M**

![Profit Curve](path_to_your_hill_chart_image.png)
*(The "Hill" demonstrates the optimal cutoff point where profit is maximized before diminishing returns set in)*

## üöÄ Technologies Used
* **CausalML / EconML**: Meta-learner implementation.
* **XGBoost**: Gradient boosting for treatment/control estimators.
* **Scikit-Learn**: Data preprocessing and pipelines.
* **Matplotlib/Seaborn**: Uplift curves and profit visualization.

## üìÇ Dataset
[Rossmann Store Sales (Kaggle)](https://www.kaggle.com/c/rossmann-store-sales/data)
